{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CPR_prediction_multivariate_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPf9xLXC/lYkoBdoOCEltXr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiddhimanRaut/Deep-Learning-based-CPR-estimation/blob/main/CPR_prediction_multivariate_LSTM_tobetrialled_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjbtJ7Bkvfl_"
      },
      "source": [
        "#Standard Imports for RNNs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Fpw_D_nSvr1R",
        "outputId": "77ec8ac9-a5ea-45a0-b694-650c4b8b1307"
      },
      "source": [
        "url = \"https://github.com/RiddhimanRaut/Deep-Learning-based-CPR-estimation/blob/main/excel_dataset.xlsx?raw=true\"\n",
        "df = pd.read_excel(url)\n",
        "#df = df[5::6] #Hour-wise Data\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date Time</th>\n",
              "      <th>CPRAVG</th>\n",
              "      <th>PROP</th>\n",
              "      <th>BUT</th>\n",
              "      <th>ETHYLENE</th>\n",
              "      <th>AI12201M</th>\n",
              "      <th>FLW</th>\n",
              "      <th>COT</th>\n",
              "      <th>TEMP</th>\n",
              "      <th>PRESS</th>\n",
              "      <th>O2</th>\n",
              "      <th>DRAFT</th>\n",
              "      <th>ETH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>01.01.2009 00:10:00</td>\n",
              "      <td>0.428151</td>\n",
              "      <td>18.960609</td>\n",
              "      <td>3.973630</td>\n",
              "      <td>29.732470</td>\n",
              "      <td>0.014431</td>\n",
              "      <td>30711.65039</td>\n",
              "      <td>820.118210</td>\n",
              "      <td>632.399261</td>\n",
              "      <td>0.466357</td>\n",
              "      <td>1.444160</td>\n",
              "      <td>-5.616851</td>\n",
              "      <td>75.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>01.01.2009 00:20:00</td>\n",
              "      <td>0.427783</td>\n",
              "      <td>18.960360</td>\n",
              "      <td>3.973562</td>\n",
              "      <td>30.123590</td>\n",
              "      <td>0.014822</td>\n",
              "      <td>30700.66016</td>\n",
              "      <td>819.662811</td>\n",
              "      <td>633.057602</td>\n",
              "      <td>0.475288</td>\n",
              "      <td>1.413894</td>\n",
              "      <td>-5.540349</td>\n",
              "      <td>75.810066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>01.01.2009 00:30:00</td>\n",
              "      <td>0.427432</td>\n",
              "      <td>19.009649</td>\n",
              "      <td>4.181924</td>\n",
              "      <td>30.477831</td>\n",
              "      <td>0.012689</td>\n",
              "      <td>30689.66016</td>\n",
              "      <td>819.886444</td>\n",
              "      <td>631.841385</td>\n",
              "      <td>0.464559</td>\n",
              "      <td>1.515123</td>\n",
              "      <td>-5.628389</td>\n",
              "      <td>75.552841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01.01.2009 00:40:00</td>\n",
              "      <td>0.427082</td>\n",
              "      <td>19.155710</td>\n",
              "      <td>3.950392</td>\n",
              "      <td>30.425819</td>\n",
              "      <td>0.012580</td>\n",
              "      <td>30678.66016</td>\n",
              "      <td>819.660172</td>\n",
              "      <td>632.495224</td>\n",
              "      <td>0.471809</td>\n",
              "      <td>1.404055</td>\n",
              "      <td>-5.576591</td>\n",
              "      <td>75.580223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>01.01.2009 00:50:00</td>\n",
              "      <td>0.426732</td>\n",
              "      <td>19.334640</td>\n",
              "      <td>3.689848</td>\n",
              "      <td>30.546061</td>\n",
              "      <td>0.012472</td>\n",
              "      <td>30667.66016</td>\n",
              "      <td>819.646805</td>\n",
              "      <td>632.388214</td>\n",
              "      <td>0.470504</td>\n",
              "      <td>1.191485</td>\n",
              "      <td>-5.274679</td>\n",
              "      <td>75.638023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Date Time    CPRAVG       PROP  ...        O2     DRAFT        ETH\n",
              "0  01.01.2009 00:10:00  0.428151  18.960609  ...  1.444160 -5.616851  75.809700\n",
              "1  01.01.2009 00:20:00  0.427783  18.960360  ...  1.413894 -5.540349  75.810066\n",
              "2  01.01.2009 00:30:00  0.427432  19.009649  ...  1.515123 -5.628389  75.552841\n",
              "3  01.01.2009 00:40:00  0.427082  19.155710  ...  1.404055 -5.576591  75.580223\n",
              "4  01.01.2009 00:50:00  0.426732  19.334640  ...  1.191485 -5.274679  75.638023\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3sGTpr1vx1D"
      },
      "source": [
        "#Separating Date and Time\n",
        "#To be used in plotting in X-axis\n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S') #pop command takes the Date Time Column out of df, so df no longer has that column."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCftdYwMQ6Co"
      },
      "source": [
        "We need to remove $Ethylene$ and $AI12201M$ columns as they are not controllable factors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBcWn2cGQ3ps",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "9f17bdf7-708a-47a4-e919-c58d5b2db7a9"
      },
      "source": [
        "df = df.drop('ETHYLENE',axis=1)\n",
        "df = df.drop('AI12201M',axis=1)\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CPRAVG</th>\n",
              "      <th>PROP</th>\n",
              "      <th>BUT</th>\n",
              "      <th>FLW</th>\n",
              "      <th>COT</th>\n",
              "      <th>TEMP</th>\n",
              "      <th>PRESS</th>\n",
              "      <th>O2</th>\n",
              "      <th>DRAFT</th>\n",
              "      <th>ETH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.428151</td>\n",
              "      <td>18.960609</td>\n",
              "      <td>3.973630</td>\n",
              "      <td>30711.65039</td>\n",
              "      <td>820.118210</td>\n",
              "      <td>632.399261</td>\n",
              "      <td>0.466357</td>\n",
              "      <td>1.444160</td>\n",
              "      <td>-5.616851</td>\n",
              "      <td>75.809700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.427783</td>\n",
              "      <td>18.960360</td>\n",
              "      <td>3.973562</td>\n",
              "      <td>30700.66016</td>\n",
              "      <td>819.662811</td>\n",
              "      <td>633.057602</td>\n",
              "      <td>0.475288</td>\n",
              "      <td>1.413894</td>\n",
              "      <td>-5.540349</td>\n",
              "      <td>75.810066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.427432</td>\n",
              "      <td>19.009649</td>\n",
              "      <td>4.181924</td>\n",
              "      <td>30689.66016</td>\n",
              "      <td>819.886444</td>\n",
              "      <td>631.841385</td>\n",
              "      <td>0.464559</td>\n",
              "      <td>1.515123</td>\n",
              "      <td>-5.628389</td>\n",
              "      <td>75.552841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.427082</td>\n",
              "      <td>19.155710</td>\n",
              "      <td>3.950392</td>\n",
              "      <td>30678.66016</td>\n",
              "      <td>819.660172</td>\n",
              "      <td>632.495224</td>\n",
              "      <td>0.471809</td>\n",
              "      <td>1.404055</td>\n",
              "      <td>-5.576591</td>\n",
              "      <td>75.580223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.426732</td>\n",
              "      <td>19.334640</td>\n",
              "      <td>3.689848</td>\n",
              "      <td>30667.66016</td>\n",
              "      <td>819.646805</td>\n",
              "      <td>632.388214</td>\n",
              "      <td>0.470504</td>\n",
              "      <td>1.191485</td>\n",
              "      <td>-5.274679</td>\n",
              "      <td>75.638023</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     CPRAVG       PROP       BUT  ...        O2     DRAFT        ETH\n",
              "0  0.428151  18.960609  3.973630  ...  1.444160 -5.616851  75.809700\n",
              "1  0.427783  18.960360  3.973562  ...  1.413894 -5.540349  75.810066\n",
              "2  0.427432  19.009649  4.181924  ...  1.515123 -5.628389  75.552841\n",
              "3  0.427082  19.155710  3.950392  ...  1.404055 -5.576591  75.580223\n",
              "4  0.426732  19.334640  3.689848  ...  1.191485 -5.274679  75.638023\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5XHP2XuxiQ6"
      },
      "source": [
        "#Variables for training\n",
        "cols = list(df)[0:df.shape[1]]\n",
        "#To enforce that values in these columns are actually float type data\n",
        "df_for_rnn = df[cols].astype(float)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "841ZEswh97NC"
      },
      "source": [
        "#Creating training_df and test_df\n",
        "n = len(df)\n",
        "training_df = df_for_rnn[0:int(n*0.7)]\n",
        "test_set = df_for_rnn[int(n*0.7):n]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERKcdfdvyGBx",
        "outputId": "19bb229d-860a-4590-f10b-3c01dddcfe12"
      },
      "source": [
        "#Scaling the Dataset\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "#scaler = StandardScaler()\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "df_for_training_scaled = scaler.fit_transform(training_df) #Scales and converts to numpy object\n",
        "print('Scaled Dataset:\\n',df_for_training_scaled)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled Dataset:\n",
            " [[0.04261512 0.39141737 0.71843606 ... 0.54553167 0.061713   0.69995722]\n",
            " [0.03834461 0.39139343 0.71841953 ... 0.53416085 0.09054363 0.69998058]\n",
            " [0.03428528 0.39611563 0.76908826 ... 0.57219227 0.05736476 0.68357295]\n",
            " ...\n",
            " [0.94817084 0.28810413 0.68416253 ... 0.67555781 0.51802072 0.79587724]\n",
            " [0.95048011 0.28807252 0.68538325 ... 0.68702255 0.51584291 0.79587529]\n",
            " [0.95188739 0.28809554 0.70426883 ... 0.68955967 0.51498322 0.79587237]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4TCtqhbzS0w",
        "outputId": "fc549fbd-abb2-40ba-9701-49597c45717b"
      },
      "source": [
        "#Readying the Multivariate Input and Univariate Output\n",
        "\n",
        "#initialisation\n",
        "trainX = [] \n",
        "trainY = []\n",
        "\n",
        "n_future = 1 #number of hours into the future\n",
        "n_past = 60  #number of hours into the past\n",
        "\n",
        "for i in range(n_past, len(df_for_training_scaled)-n_future+1):\n",
        "  trainX.append(df_for_training_scaled[i-60:i,1:10])\n",
        "  trainY.append(df_for_training_scaled[i+n_future-1:i+n_future,0])\n",
        "trainX = np.array(trainX)   # shape 1: no of records, shape 2: past_days, shape 3: input_cols\n",
        "trainY = np.array(trainY)   # shape 1: records, shape 2: future prediction data\n",
        "print('TrainX shape = (%d,%d,%d)'%(trainX.shape[0],trainX.shape[1],trainX.shape[2]))\n",
        "print('TrainY shape = (%d,%d)'%(trainY.shape[0],trainY.shape[1]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TrainX shape = (8667,60,9)\n",
            "TrainY shape = (8667,1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh52q_PG4VSD",
        "outputId": "0c0db724-ef0a-4619-9ed1-cbb5d2affe77"
      },
      "source": [
        "# Part 2 - Building the RNN\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "model = Sequential()\n",
        "model.add(LSTM(64,activation='sigmoid',return_sequences=True,input_shape = (trainX.shape[1],trainX.shape[2])))\n",
        "model.add(LSTM(32,activation='sigmoid',return_sequences=False, recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(trainY.shape[1]))\n",
        "\n",
        "model.compile(optimizer='adam',loss = 'mse')\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 60, 64)            18944     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 31,393\n",
            "Trainable params: 31,393\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xj9Y8Sq7dBj",
        "outputId": "20e3285f-f7a8-429f-c3c9-e6c7e23ec871"
      },
      "source": [
        "#Let's traaaaaaaaaaaainnn\n",
        "\n",
        "history = model.fit(trainX,trainY,epochs=200,batch_size= 32,verbose=1,validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "244/244 [==============================] - 69s 188ms/step - loss: 0.6210 - val_loss: 0.2530\n",
            "Epoch 2/200\n",
            "244/244 [==============================] - 46s 187ms/step - loss: 0.2261 - val_loss: 0.1860\n",
            "Epoch 3/200\n",
            "244/244 [==============================] - 45s 183ms/step - loss: 0.1142 - val_loss: 0.0831\n",
            "Epoch 4/200\n",
            "244/244 [==============================] - 45s 186ms/step - loss: 0.0623 - val_loss: 0.0468\n",
            "Epoch 5/200\n",
            "244/244 [==============================] - 45s 185ms/step - loss: 0.0350 - val_loss: 0.0315\n",
            "Epoch 6/200\n",
            "244/244 [==============================] - 45s 183ms/step - loss: 0.0202 - val_loss: 0.0112\n",
            "Epoch 7/200\n",
            "244/244 [==============================] - 46s 187ms/step - loss: 0.0142 - val_loss: 0.0173\n",
            "Epoch 8/200\n",
            "244/244 [==============================] - 44s 179ms/step - loss: 0.0106 - val_loss: 0.0097\n",
            "Epoch 9/200\n",
            "244/244 [==============================] - 45s 183ms/step - loss: 0.0094 - val_loss: 0.0149\n",
            "Epoch 10/200\n",
            "244/244 [==============================] - 44s 179ms/step - loss: 0.0083 - val_loss: 0.0091\n",
            "Epoch 11/200\n",
            "244/244 [==============================] - 41s 170ms/step - loss: 0.0071 - val_loss: 0.0124\n",
            "Epoch 12/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0067 - val_loss: 0.0138\n",
            "Epoch 13/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0060 - val_loss: 0.0088\n",
            "Epoch 14/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0056 - val_loss: 0.0164\n",
            "Epoch 15/200\n",
            "244/244 [==============================] - 40s 166ms/step - loss: 0.0055 - val_loss: 0.0160\n",
            "Epoch 16/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0046 - val_loss: 0.0206\n",
            "Epoch 17/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0048 - val_loss: 0.0140\n",
            "Epoch 18/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0042 - val_loss: 0.0153\n",
            "Epoch 19/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0042 - val_loss: 0.0114\n",
            "Epoch 20/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0042 - val_loss: 0.0130\n",
            "Epoch 21/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0038 - val_loss: 0.0123\n",
            "Epoch 22/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0038 - val_loss: 0.0111\n",
            "Epoch 23/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0038 - val_loss: 0.0187\n",
            "Epoch 24/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0035 - val_loss: 0.0151\n",
            "Epoch 25/200\n",
            "244/244 [==============================] - 42s 170ms/step - loss: 0.0035 - val_loss: 0.0145\n",
            "Epoch 26/200\n",
            "244/244 [==============================] - 42s 170ms/step - loss: 0.0034 - val_loss: 0.0094\n",
            "Epoch 27/200\n",
            "244/244 [==============================] - 40s 165ms/step - loss: 0.0034 - val_loss: 0.0177\n",
            "Epoch 28/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0032 - val_loss: 0.0120\n",
            "Epoch 29/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0032 - val_loss: 0.0151\n",
            "Epoch 30/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0030 - val_loss: 0.0146\n",
            "Epoch 31/200\n",
            "244/244 [==============================] - 40s 166ms/step - loss: 0.0031 - val_loss: 0.0179\n",
            "Epoch 32/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0030 - val_loss: 0.0159\n",
            "Epoch 33/200\n",
            "244/244 [==============================] - 41s 170ms/step - loss: 0.0029 - val_loss: 0.0138\n",
            "Epoch 34/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0030 - val_loss: 0.0109\n",
            "Epoch 35/200\n",
            "244/244 [==============================] - 41s 170ms/step - loss: 0.0029 - val_loss: 0.0115\n",
            "Epoch 36/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0029 - val_loss: 0.0105\n",
            "Epoch 37/200\n",
            "244/244 [==============================] - 41s 170ms/step - loss: 0.0028 - val_loss: 0.0121\n",
            "Epoch 38/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0028 - val_loss: 0.0122\n",
            "Epoch 39/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0025 - val_loss: 0.0119\n",
            "Epoch 40/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0026 - val_loss: 0.0121\n",
            "Epoch 41/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0028 - val_loss: 0.0133\n",
            "Epoch 42/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0023 - val_loss: 0.0120\n",
            "Epoch 43/200\n",
            "244/244 [==============================] - 43s 175ms/step - loss: 0.0023 - val_loss: 0.0099\n",
            "Epoch 44/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0024 - val_loss: 0.0127\n",
            "Epoch 45/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0023 - val_loss: 0.0187\n",
            "Epoch 46/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0023 - val_loss: 0.0162\n",
            "Epoch 47/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0024 - val_loss: 0.0079\n",
            "Epoch 48/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0024 - val_loss: 0.0162\n",
            "Epoch 49/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0022 - val_loss: 0.0119\n",
            "Epoch 50/200\n",
            "244/244 [==============================] - 41s 167ms/step - loss: 0.0022 - val_loss: 0.0095\n",
            "Epoch 51/200\n",
            "244/244 [==============================] - 43s 175ms/step - loss: 0.0021 - val_loss: 0.0076\n",
            "Epoch 52/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0022 - val_loss: 0.0103\n",
            "Epoch 53/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0022 - val_loss: 0.0111\n",
            "Epoch 54/200\n",
            "244/244 [==============================] - 43s 176ms/step - loss: 0.0021 - val_loss: 0.0088\n",
            "Epoch 55/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0023 - val_loss: 0.0100\n",
            "Epoch 56/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0020 - val_loss: 0.0104\n",
            "Epoch 57/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 58/200\n",
            "244/244 [==============================] - 43s 176ms/step - loss: 0.0019 - val_loss: 0.0104\n",
            "Epoch 59/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0019 - val_loss: 0.0091\n",
            "Epoch 60/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0020 - val_loss: 0.0096\n",
            "Epoch 61/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0026 - val_loss: 0.0071\n",
            "Epoch 62/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0018 - val_loss: 0.0106\n",
            "Epoch 63/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0023 - val_loss: 0.0082\n",
            "Epoch 64/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0019 - val_loss: 0.0086\n",
            "Epoch 65/200\n",
            "244/244 [==============================] - 43s 175ms/step - loss: 0.0018 - val_loss: 0.0082\n",
            "Epoch 66/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0018 - val_loss: 0.0064\n",
            "Epoch 67/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0018 - val_loss: 0.0092\n",
            "Epoch 68/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0018 - val_loss: 0.0095\n",
            "Epoch 69/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0018 - val_loss: 0.0051\n",
            "Epoch 70/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0017 - val_loss: 0.0050\n",
            "Epoch 71/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0018 - val_loss: 0.0076\n",
            "Epoch 72/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0017 - val_loss: 0.0125\n",
            "Epoch 73/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0017 - val_loss: 0.0117\n",
            "Epoch 74/200\n",
            "244/244 [==============================] - 42s 174ms/step - loss: 0.0017 - val_loss: 0.0064\n",
            "Epoch 75/200\n",
            "244/244 [==============================] - 43s 176ms/step - loss: 0.0017 - val_loss: 0.0090\n",
            "Epoch 76/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0019 - val_loss: 0.0064\n",
            "Epoch 77/200\n",
            "244/244 [==============================] - 43s 177ms/step - loss: 0.0027 - val_loss: 0.0084\n",
            "Epoch 78/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0015 - val_loss: 0.0056\n",
            "Epoch 79/200\n",
            "244/244 [==============================] - 43s 176ms/step - loss: 0.0016 - val_loss: 0.0045\n",
            "Epoch 80/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0016 - val_loss: 0.0064\n",
            "Epoch 81/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0015 - val_loss: 0.0044\n",
            "Epoch 82/200\n",
            "244/244 [==============================] - 43s 176ms/step - loss: 0.0015 - val_loss: 0.0050\n",
            "Epoch 83/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0016 - val_loss: 0.0177\n",
            "Epoch 84/200\n",
            "244/244 [==============================] - 44s 180ms/step - loss: 0.0016 - val_loss: 0.0063\n",
            "Epoch 85/200\n",
            "244/244 [==============================] - 42s 170ms/step - loss: 0.0015 - val_loss: 0.0052\n",
            "Epoch 86/200\n",
            "244/244 [==============================] - 43s 175ms/step - loss: 0.0015 - val_loss: 0.0036\n",
            "Epoch 87/200\n",
            "244/244 [==============================] - 42s 172ms/step - loss: 0.0016 - val_loss: 0.0037\n",
            "Epoch 88/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0016 - val_loss: 0.0048\n",
            "Epoch 89/200\n",
            "244/244 [==============================] - 43s 175ms/step - loss: 0.0014 - val_loss: 0.0042\n",
            "Epoch 90/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0015 - val_loss: 0.0050\n",
            "Epoch 91/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0014 - val_loss: 0.0060\n",
            "Epoch 92/200\n",
            "244/244 [==============================] - 42s 171ms/step - loss: 0.0014 - val_loss: 0.0040\n",
            "Epoch 93/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0014 - val_loss: 0.0048\n",
            "Epoch 94/200\n",
            "244/244 [==============================] - 41s 167ms/step - loss: 0.0015 - val_loss: 0.0049\n",
            "Epoch 95/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 96/200\n",
            "244/244 [==============================] - 41s 169ms/step - loss: 0.0014 - val_loss: 0.0043\n",
            "Epoch 97/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0015 - val_loss: 0.0046\n",
            "Epoch 98/200\n",
            "244/244 [==============================] - 42s 170ms/step - loss: 0.0014 - val_loss: 0.0036\n",
            "Epoch 99/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0014 - val_loss: 0.0049\n",
            "Epoch 100/200\n",
            "244/244 [==============================] - 43s 175ms/step - loss: 0.0014 - val_loss: 0.0038\n",
            "Epoch 101/200\n",
            "244/244 [==============================] - 41s 167ms/step - loss: 0.0014 - val_loss: 0.0057\n",
            "Epoch 102/200\n",
            "244/244 [==============================] - 42s 173ms/step - loss: 0.0013 - val_loss: 0.0043\n",
            "Epoch 103/200\n",
            "244/244 [==============================] - 41s 168ms/step - loss: 0.0014 - val_loss: 0.0042\n",
            "Epoch 104/200\n",
            "159/244 [==================>...........] - ETA: 14s - loss: 0.0013"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncCu99ox8fsz"
      },
      "source": [
        "plt.plot(history.history['loss'],label = 'Training Loss')\n",
        "plt.plot(history.history['val_loss'],label = 'Validation Loss')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pk93fzhGAmN7"
      },
      "source": [
        "test_df_scaled = scaler.transform(test_set)\n",
        "testX = []\n",
        "for i in range(n_past,len(test_df_scaled)+n_future-1):\n",
        "  testX.append(test_df_scaled[i-n_past:i,1:10])\n",
        "testX = np.array(testX)\n",
        "testX.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh8WcrvuDuqU"
      },
      "source": [
        "predicted_CPRAVG = model.predict(testX)\n",
        "predicted_CPRAVG = np.repeat(predicted_CPRAVG,test_df_scaled.shape[1],axis = -1)\n",
        "predicted_CPRAVG = scaler.inverse_transform(predicted_CPRAVG)[:,0]\n",
        "predicted_CPRAVG = predicted_CPRAVG.reshape(-1,1)\n",
        "print(predicted_CPRAVG)\n",
        "predicted_CPRAVGplot = np.empty_like(df)\n",
        "predicted_CPRAVGplot[:,:] = np.nan\n",
        "predicted_CPRAVGplot[training_df.shape[0]+n_past:df.shape[0],:] = predicted_CPRAVG\n",
        "plt.plot(df['CPRAVG'],color = 'red', label = 'Real CPR avg')\n",
        "plt.plot(predicted_CPRAVGplot[:,0], color = 'blue', label = 'Predicted CPR avg')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXQXS-DI5z8"
      },
      "source": [
        "Time to predict the future!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKkpXA3rT0IY"
      },
      "source": [
        "We shall use the previous $200$ data predict $CPRAVG$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zheZY4EQUFME"
      },
      "source": [
        "# starting_record = df.shape[0]\n",
        "# CPRAVG_real_values = df['CPRAVG']\n",
        "url_future = \"https://raw.githubusercontent.com/RiddhimanRaut/Deep-Learning-based-CPR-estimation/main/Future_test_dataset.csv\"\n",
        "df_future = pd.read_csv(url_future)\n",
        "df_future.drop(df_future.columns[10],axis = 1, inplace=True)\n",
        "new_df_train = df_future[0:df_future.shape[0]-1000]\n",
        "new_df_test = df_future[df_future.shape[0]-1000:df_future.shape[0]]\n",
        "temp = pd.DataFrame.to_numpy(new_df_train)\n",
        "length_of_future_prediction = new_df_test.shape[0]\n",
        "for i in range(length_of_future_prediction):   #Take past 200 data, predict next 1000 values\n",
        "  print(\"Predicting CPRAVG for entry:\",i)\n",
        "  #Gathering the past 200 data\n",
        "  total_df_length = temp.shape[0]\n",
        "  future_Xinput = temp[total_df_length - 200:total_df_length]\n",
        "  future_Xinput_scaled = scaler.transform(future_Xinput)\n",
        "  future_Xinput_scaled_batch = np.array([future_Xinput_scaled[:,1:10]])\n",
        "  future_prediction = model.predict(future_Xinput_scaled_batch)\n",
        "  future_prediction = np.repeat(future_prediction, future_Xinput_scaled.shape[1],axis = -1)\n",
        "  future_prediction = scaler.inverse_transform(future_prediction)[:,0]\n",
        "  #Parameters to be set:\n",
        "  # future_data = df_future.loc[total_df_length - 200+i]\n",
        "  # future_data = pd.DataFrame.to_numpy(future_data)\n",
        "  # future_data = future_data[0:10]\n",
        "  future_data = new_df_test.loc[new_df_train.shape[0]+i]\n",
        "  future_data = pd.DataFrame.to_numpy(future_data)\n",
        "  future_data\n",
        "  future_data[0] = future_prediction[0]\n",
        "  future_data = future_data.reshape(1,10)\n",
        "  temp = np.append(temp,future_data, axis = 0)\n",
        "future_data_numpy = temp[new_df_train.shape[0]:new_df_train.shape[0]+new_df_test.shape[0],:]\n",
        "CPRAVG_predicted_values = future_data_numpy[:,0]\n",
        "# print(CPRAVG_predicted_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4l1roJQDrLa"
      },
      "source": [
        "# url_future = \"https://raw.githubusercontent.com/RiddhimanRaut/Deep-Learning-based-CPR-estimation/main/Future_test_dataset.csv\"\n",
        "# new_training_dataset = pd.read_csv(url_future)\n",
        "# new_training_dataset.drop(new_training_dataset.columns[10], axis = 1, inplace=True)\n",
        "# new_training_dataset_scaled = scaler.transform(new_training_dataset)\n",
        "# length_of_whole_dataset = new_training_dataset.shape[0]\n",
        "# new_n_future = 1\n",
        "# new_n_past = 200\n",
        "# for i in range(length_of_whole_dataset-1000,length_of_whole_dataset):\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1a4TTp0c2UF"
      },
      "source": [
        "plt.plot(CPRAVG_predicted_values,color = 'blue', label = 'Predicted CPR avg')\n",
        "df_future2 = pd.read_csv(url_future)\n",
        "new_CPRAVG = df_future2['CPRAVG'][new_df_train.shape[0]:new_df_train.shape[0]+new_df_test.shape[0]]\n",
        "new_CPRAVG = pd.DataFrame.to_numpy(new_CPRAVG)\n",
        "# print(new_CPRAVG)\n",
        "plt.plot(new_CPRAVG,color = 'red', label = 'New CPR avg')\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW1zByG3_54L"
      },
      "source": [
        "while True:pass\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}